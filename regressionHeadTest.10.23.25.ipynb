{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7cdc324-548e-4a94-a218-6fcfb6654405",
   "metadata": {},
   "source": [
    "# Model Playground Testing\n",
    "I am trying to make sure my masked language model (MLM) works first before I try to do anything with changing the head especially to a predictive model head.\n",
    "\n",
    "This was last modified 10/23/2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dbe6a14-b615-4b7b-8fa8-635299fce4fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device = cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at rafalposwiata/deproberta-large-v1 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1: 100%|███████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  5.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 2: 100%|███████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 10.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.3797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 3: 100%|███████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 11.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.9005\n",
      "\n",
      "text: I can’t focus on anything lately.\n",
      "score: 0.6301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# DepRoBERTa large + predictive head (for depression scoring or whatever)\n",
    "# I’m just testing this version on my GPU (4070, CUDA 12.4)\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"device =\", device)\n",
    "\n",
    "# load base model + tokenizer\n",
    "model_name = \"rafalposwiata/deproberta-large-v1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "base_model = AutoModel.from_pretrained(model_name).to(device)\n",
    "\n",
    "print(\"model loaded on\", device)\n",
    "\n",
    "# attach a simple regression head\n",
    "class DepPredictor(nn.Module):\n",
    "    def __init__(self, base):\n",
    "        super().__init__()\n",
    "        self.base = base\n",
    "        self.drop = nn.Dropout(0.3)\n",
    "        self.fc = nn.Linear(base.config.hidden_size, 1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        out = self.base(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls = out.last_hidden_state[:, 0]  # CLS token\n",
    "        return self.fc(self.drop(cls))\n",
    "\n",
    "model = DepPredictor(base_model).to(device)\n",
    "\n",
    "# some dummy training samples (replace with your dataset later)\n",
    "texts = [\n",
    "    \"I feel sad and tired.\",\n",
    "    \"I’m doing okay today.\",\n",
    "    \"Everything feels meaningless.\",\n",
    "    \"I’m feeling better lately.\"\n",
    "]\n",
    "targets = [0.9, 0.2, 0.95, 0.3]  # just random values between 0 and 1\n",
    "\n",
    "class TextData(Dataset):\n",
    "    def __init__(self, texts, y, tok, max_len=64):\n",
    "        self.texts = texts\n",
    "        self.y = y\n",
    "        self.tok = tok\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        enc = self.tok(\n",
    "            self.texts[i],\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_len,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\": enc[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": enc[\"attention_mask\"].squeeze(0),\n",
    "            \"target\": torch.tensor(self.y[i], dtype=torch.float32)\n",
    "        }\n",
    "\n",
    "data = TextData(texts, targets, tokenizer)\n",
    "loader = DataLoader(data, batch_size=2, shuffle=True)\n",
    "\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# simple training loop\n",
    "model.train()\n",
    "for ep in range(3):\n",
    "    total = 0\n",
    "    for batch in tqdm(loader, desc=f\"epoch {ep+1}\"):\n",
    "        opt.zero_grad()\n",
    "        ids = batch[\"input_ids\"].to(device)\n",
    "        mask = batch[\"attention_mask\"].to(device)\n",
    "        y = batch[\"target\"].unsqueeze(1).to(device)\n",
    "        pred = model(ids, mask)\n",
    "        loss = loss_fn(pred, y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        total += loss.item()\n",
    "    print(\"loss:\", round(total / len(loader), 4))\n",
    "\n",
    "# quick test\n",
    "model.eval()\n",
    "txt = \"I can’t focus on anything lately.\"\n",
    "x = tokenizer(txt, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "with torch.no_grad():\n",
    "    pred = model(x[\"input_ids\"], x[\"attention_mask\"]).item()\n",
    "print(f\"\\ntext: {txt}\\nscore: {pred:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a970041a-d988-4900-9d00-a4b040fbfff4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba2710f-acb4-4c9d-8191-03c7fd8d585a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
